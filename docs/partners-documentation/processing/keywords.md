---
title: Mots-cl√©s
parent: ‚öôÔ∏è Traitements des donn√©es
layout: default
nav_order: 3.2.1
---

# Identification de mots-cl√©s associ√©s aux formations
{: .no_toc }

- TOC
{:toc}

## Objectif

Pouvoir faire une recherche de formation √† partir de mots-cl√©s (pas forc√©ment pr√©sents dans le titre ou la description).

## Solution retenue

Plusieurs pistes ont √©t√© explor√©es (notamment en utilisant des solutions d'IA telles que Mistral ou ChatGPT).

Nous avons finalement opt√© pour l'utlisation de keybert via le mod√®le NLP ‚Äúdistiluse-base-multilingual-cased-v1‚Äù. Il s‚Äôagit d‚Äôune solution open source.

## Script

```python
from keybert import KeyBERT
from sentence_transformers import SentenceTransformer
import nltk
import spacy
from nltk.corpus import stopwords
import pandas as pd
from tqdm import tqdm

# Chargement des mod√®les
model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
kw_model = KeyBERT(model)

# T√©l√©chargement des stopwords fran√ßais
nltk.download('stopwords')
french_stopwords = stopwords.words('french')

# Chargement du mod√®le spaCy fran√ßais
nlp = spacy.load("fr_core_news_md")  # Si pas install√© : python -m spacy download fr_core_news_md

# Fonction de pr√©traitement : minuscule + lemmatisation
def preprocess_text(text):
    doc = nlp(text.lower())  # Mise en minuscule ici
    lemmatized_text = " ".join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])
    return lemmatized_text

# Extraction des mots-cl√©s
def extract_keywords_from_text(text, top_n=10, min_score=0.1):
    preprocessed = preprocess_text(text)
    keywords = kw_model.extract_keywords(preprocessed, top_n=top_n, stop_words=french_stopwords)
    
    lemmatized_keywords = []
    for kw, score in keywords:
        if score >= min_score:
            doc = nlp(kw)
            lemma = " ".join([token.lemma_ for token in doc])
            lemmatized_keywords.append((lemma, score))
    return lemmatized_keywords

def extract_keywords_from_list(text_list, top_n=10, min_score=0.1):
    all_results = []
    for i, text in enumerate(tqdm(text_list, desc="üîç Traitement des textes", unit="texte")):
        keywords = extract_keywords_from_text(text, top_n=top_n, min_score=min_score)
        for lemma, score in keywords:
            all_results.append({
                "id": i,
                "mot_clef": lemma,
                "score": score
            })
    return all_results
  

def extract_keywords_as_dataframe(text_list, top_n=10, min_score=0.1):
    results = extract_keywords_from_list(text_list, top_n, min_score)
    return pd.DataFrame(results)

```

## üéØ √Ä quoi sert ce script ?

Ce script permet **d'extraire automatiquement les mots-cl√©s les plus importants** d'un ou plusieurs textes en fran√ßais.

Ces mots-cl√©s peuvent ensuite √™tre utilis√©s pour **faire des recherches**, **organiser des documents**, **r√©sumer des contenus**, etc.

## üõ†Ô∏è Comment fonctionne le script ? (explication √©tape par √©tape)

1. **Importation des outils n√©cessaires**
    - **KeyBERT** : un outil pour trouver les mots-cl√©s d‚Äôun texte en utilisant l‚Äôintelligence artificielle.
    - **SentenceTransformer** : un mod√®le d‚ÄôIA qui transforme des phrases en "vecteurs" pour que l‚Äôordinateur puisse les comparer.
    - **NLTK** et **spaCy** : deux biblioth√®ques pour le traitement automatique du texte (comme retirer les mots inutiles ou simplifier les mots).
    - **Pandas** : une biblioth√®que pour organiser les r√©sultats dans un tableau.
    - **tqdm** : un outil pour afficher une barre de progression (pratique quand il y a beaucoup de textes √† traiter).
2. **Pr√©paration des outils**
    - T√©l√©chargement de la liste des **mots vides en fran√ßais** (ex : "le", "de", "un", "et", qui n'apportent pas beaucoup de sens).
    - Chargement d'un mod√®le de compr√©hension du fran√ßais avec **spaCy**.
    - Pr√©paration du mod√®le **KeyBERT** qui sera utilis√© pour extraire les mots-cl√©s.
3. **Pr√©traitement des textes**
    - Chaque texte est **converti en minuscules** (ex : "Bonjour" devient "bonjour") pour uniformiser l'analyse.
    - Chaque mot est **simplifi√© √† sa racine** (ex : "√©tudiants" devient "√©tudiant", "couraient" devient "courir"). Cela s'appelle la **lemmatisation**.
    - La ponctuation et les espaces inutiles sont supprim√©s.
4. **Extraction des mots-cl√©s d‚Äôun texte**
    - Le texte nettoy√© est envoy√© au mod√®le **KeyBERT**.
    - Le mod√®le renvoie une liste de mots-cl√©s avec un **score** (plus le score est √©lev√©, plus le mot-cl√© est pertinent par rapport au texte).
    - Seuls les mots-cl√©s dont le score est sup√©rieur √† un certain seuil (ex : 0.1) sont conserv√©s.
    - Les mots-cl√©s sont aussi **lemmatis√©s** pour √©viter d‚Äôavoir plusieurs versions d‚Äôun m√™me mot (ex: "marcher", "marche", "marchait" ‚Üí "marcher").
5. **Traitement d'une liste de textes**
    - Si on a plusieurs textes, le script :
        - Traite chaque texte un par un (avec une barre de progression).
        - Extrait les mots-cl√©s pour chaque texte.
        - Associe √† chaque mot-cl√© l‚Äôidentifiant du texte auquel il appartient.
6. **Mise en forme des r√©sultats**
    - √Ä la fin, les r√©sultats sont mis dans un **tableau (DataFrame)** avec trois colonnes :
        - `id` : le num√©ro du texte d‚Äôorigine
        - `mot_clef` : le mot-cl√© extrait
        - `score` : la pertinence du mot-cl√©